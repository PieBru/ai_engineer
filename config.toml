# AI Engineer Configuration File
# Non-sensitive settings can be defined here.
# Sensitive settings like API keys should be in your .env file.

[litellm]
# The model name to use with LiteLLM.
# Examples: "deepseek-reasoner", "gpt-4o", "claude-3-opus-20240229", "openrouter/deepseek/deepseek-chat"
# If not set here or via environment variable, defaults to "deepseek-reasoner".
# The LITELLM_MODEL environment variable (e.g., from .env or shell) takes precedence over this setting.
model = "deepseek-reasoner"

# The API base URL for LiteLLM.
# Examples: "https://api.deepseek.com/v1", "https://api.openai.com/v1", "https://openrouter.ai/api/v1"
# If not set here or via environment variable, defaults to "https://api.deepseek.com/v1".
# The LITELLM_API_BASE environment variable (e.g., from .env or shell) takes precedence over this setting.
api_base = "https://api.deepseek.com/v1"

[ui]
# Controls the verbosity of the AI's reasoning process output.
# Possible values:
#   "full"    - (Default) Shows the complete reasoning text.
#   "compact" - Shows "ðŸ’­ Reasoning..." once, then prints dots for progress.
#   "silent"  - Suppresses reasoning output entirely.
# The REASONING_STYLE environment variable takes precedence over this setting.
reasoning_style = "full"
